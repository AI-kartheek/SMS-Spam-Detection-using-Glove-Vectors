{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GloVe Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloaded Golve Vectors from here : https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "GloVe Vectors(Global Vectors) is an unsupervised learning algorithm for obtaining vector representations for words.\n",
    "It shows the similarities and differences between words as a vector representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## we set the seed so that we receive the same random weights at each time we train the program\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Flatten,Embedding,Activation,Dropout\n",
    "from tensorflow.keras.layers import Conv1D,MaxPooling1D,GlobalMaxPooling1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/spam.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will �_ b going to esplanade fr home?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        v1                                                 v2 Unnamed: 2  \\\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...        NaN   \n",
       "5568   ham              Will �_ b going to esplanade fr home?        NaN   \n",
       "5569   ham  Pity, * was in mood for that. So...any other s...        NaN   \n",
       "5570   ham  The guy did some bitching but I acted like i'd...        NaN   \n",
       "5571   ham                         Rofl. Its true to its name        NaN   \n",
       "\n",
       "     Unnamed: 3 Unnamed: 4  \n",
       "5567        NaN        NaN  \n",
       "5568        NaN        NaN  \n",
       "5569        NaN        NaN  \n",
       "5570        NaN        NaN  \n",
       "5571        NaN        NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                             review\n",
       "0       ham  Go until jurong point, crazy.. Available only ...\n",
       "1       ham                      Ok lar... Joking wif u oni...\n",
       "2      spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       ham  U dun say so early hor... U c already then say...\n",
       "4       ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns = ['Unnamed: 2','Unnamed: 3','Unnamed: 4'], inplace = True)\n",
    "df.columns = ['sentiment','review']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                             review  spam\n",
       "0       ham  Go until jurong point, crazy.. Available only ...     0\n",
       "1       ham                      Ok lar... Joking wif u oni...     0\n",
       "2      spam  Free entry in 2 a wkly comp to win FA Cup fina...     1\n",
       "3       ham  U dun say so early hor... U c already then say...     0\n",
       "4       ham  Nah I don't think he goes to usf, he lives aro...     0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['spam'] = pd.get_dummies(df['sentiment'],drop_first=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  spam\n",
       "0  Go until jurong point, crazy.. Available only ...     0\n",
       "1                      Ok lar... Joking wif u oni...     0\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...     1\n",
       "3  U dun say so early hor... U c already then say...     0\n",
       "4  Nah I don't think he goes to usf, he lives aro...     0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns = ['sentiment'], inplace=True)\n",
    "df.head() \n",
    "# 0 for ham and 1 for spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4825\n",
       "1     747\n",
       "Name: spam, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['spam'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you\n",
      "I would\n",
      "we will have\n"
     ]
    }
   ],
   "source": [
    "import contractions as cont # to fix the contractions we use this library\n",
    "\n",
    "print(cont.fix(\"u\"))\n",
    "print(cont.fix(\"i'd\"))\n",
    "print(cont.fix(\"we'll've\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import unicodedata\n",
    "import contractions as cont # to fix the contractions we use this library\n",
    "\n",
    "def DataCleaner(x):\n",
    "    x = BeautifulSoup(x, 'html.parser').get_text() # remove html tags\n",
    "    x = re.sub(r'(http|ftp|https)\\S+\\s*', '', x)  # remove URLs\n",
    "    x = re.sub(r'([a-zA-Z0-9+._-]+@[a-zA-Z0-9._-]+\\.[a-zA-Z0-9_-]+)', '', x) # remove Emails\n",
    "    x = unicodedata.normalize('NFKD', x).encode('ascii', 'ignore').decode('utf-8', 'ignore') # remove Accented Text\n",
    "    x = \" \".join([cont.fix(word.lower()) for word in x.split()]) # we expand the contraction of words\n",
    "    x = re.sub('[^a-zA-Z]+', ' ', x) # here we replace all with a space character except for alphabets.\n",
    "    x = \" \".join([word.lower() for word in x.split()])  # remove extra whitespace around the words.\n",
    "    return x\n",
    "\n",
    "# we haven't removed the stop words here because glove vectors also contain vector representation for the stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ok lar joking wif you oni</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>free entry in a wkly comp to win fa cup final ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>you dun say so early hor you c already then say</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nah i do not think he goes to usf he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  spam\n",
       "0  go until jurong point crazy available only in ...     0\n",
       "1                          ok lar joking wif you oni     0\n",
       "2  free entry in a wkly comp to win fa cup final ...     1\n",
       "3    you dun say so early hor you c already then say     0\n",
       "4  nah i do not think he goes to usf he lives aro...     0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'] = df['review'].apply(lambda x: DataCleaner(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>this is the nd time we have tried contact you ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>will b going to esplanade fr home</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>pity was in mood for that so any other suggest...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>the guy did some bitching but i acted like i w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>rofl its true to its name</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review  spam\n",
       "5567  this is the nd time we have tried contact you ...     1\n",
       "5568                  will b going to esplanade fr home     0\n",
       "5569  pity was in mood for that so any other suggest...     0\n",
       "5570  the guy did some bitching but i acted like i w...     0\n",
       "5571                          rofl its true to its name     0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go until jurong point crazy available only in bugis n great world la e buffet cine there got amore wat',\n",
       " 'ok lar joking wif you oni',\n",
       " 'free entry in a wkly comp to win fa cup final tkts st may text fa to to receive entry question std txt rate t c s apply over s']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = df['review'].tolist()\n",
    "text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = Tokenizer()\n",
    "token.fit_on_texts(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7636"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(token.word_index)+1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#token.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[45,\n",
       "  444,\n",
       "  3859,\n",
       "  777,\n",
       "  701,\n",
       "  619,\n",
       "  65,\n",
       "  9,\n",
       "  1226,\n",
       "  73,\n",
       "  117,\n",
       "  319,\n",
       "  939,\n",
       "  143,\n",
       "  2676,\n",
       "  1227,\n",
       "  58,\n",
       "  51,\n",
       "  3860,\n",
       "  130],\n",
       " [43, 320, 1374, 445, 1, 1766]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text = token.texts_to_sequences(text)\n",
    "encoded_text[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum array length 190 and it is present at index of 1084\n"
     ]
    }
   ],
   "source": [
    "# getting maximum sentence length and its position \n",
    "\n",
    "max_length = len(encoded_text[0])\n",
    "max_ind = 0\n",
    "for i, arr in enumerate(encoded_text):\n",
    "    if max_length < len(arr):\n",
    "        max_length = len(arr)\n",
    "        max_ind = i\n",
    "print(\"maximum array length {} and it is present at index of {}\".format(max_length, max_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## it shows an array of maximum length \n",
    "#encoded_text[max_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = max_length + 10  # just adding extra length to make it 200 dimension\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 200)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pad_sequences(encoded_text, maxlen = max_len, padding = 'pre')\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,   45,  444, 3859,  777,  701,  619,   65,\n",
       "           9, 1226,   73,  117,  319,  939,  143, 2676, 1227,   58,   51,\n",
       "        3860,  130],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,   43,  320, 1374,  445,\n",
       "           1, 1766]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GloVe Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vectors = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Make a dictionary of glove vectors.\n",
    "\n",
    "file = open('GloVe models/glove.6B.200d.txt', encoding = 'utf-8')\n",
    "\n",
    "for line in file:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vectors = np.asarray(values[1:])\n",
    "    glove_vectors[word] = vectors\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " ',',\n",
       " '.',\n",
       " 'of',\n",
       " 'to',\n",
       " 'and',\n",
       " 'in',\n",
       " 'a',\n",
       " '\"',\n",
       " \"'s\",\n",
       " 'for',\n",
       " '-',\n",
       " 'that',\n",
       " 'on',\n",
       " 'is']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = glove_vectors.keys()\n",
    "list(keys)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glove_vectors.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors.get('you').shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Checking for other words as it returns None value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "a =glove_vectors.get('asciii')\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## matching and making a vector of words present in glove_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7636, 200)\n"
     ]
    }
   ],
   "source": [
    "word_vector_matrix = np.zeros(shape=(vocab_size, max_len))   \n",
    "print(word_vector_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "unMatched_words = []\n",
    "for word, index in token.word_index.items():\n",
    "    vector = glove_vectors.get(word)\n",
    "    \n",
    "    if vector is not None:\n",
    "        word_vector_matrix[index] = vector\n",
    "    else:\n",
    "        unMatched_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300 words present in the dataset that are not matched with glove vectors.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['pobox',\n",
       " 'aight',\n",
       " 'thanx',\n",
       " 'optout',\n",
       " 'chikku',\n",
       " 'mths',\n",
       " 'msgs',\n",
       " 'knw',\n",
       " 'frnd',\n",
       " 'boytoy']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"{} words present in the dataset that are not matched with glove vectors.\".format(len(unMatched_words)))\n",
    "unMatched_words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* word_vector_matrix -- contains the weights from glove vectors for each matched word in X and remaining unmatched words make into zeroes...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ],\n",
       "       [ 0.85395  ,  0.57146  , -0.023652 , -0.11047  , -0.1275   ,\n",
       "         0.085129 , -0.74976  , -0.068121 ,  0.043576 ,  0.63928  ,\n",
       "        -0.072301 ,  0.28775  ,  0.66309  ,  0.23428  , -0.080206 ,\n",
       "         0.27575  , -0.30429  ,  0.36573  ,  0.14379  , -0.107    ,\n",
       "         0.33497  ,  3.0789   ,  0.059451 ,  0.039004 ,  0.45507  ,\n",
       "        -0.47595  , -0.10247  ,  0.28632  , -0.31317  , -0.053495 ,\n",
       "        -0.1799   , -0.075404 ,  0.11216  , -0.098163 , -0.10058  ,\n",
       "        -0.33414  , -0.52159  , -0.17538  ,  0.008864 ,  0.30078  ,\n",
       "         0.083636 ,  0.38333  , -0.12608  ,  0.47973  , -0.33916  ,\n",
       "         0.34158  ,  1.0214   , -0.15934  ,  0.09167  ,  0.42668  ,\n",
       "         0.30747  , -0.10632  ,  0.051894 ,  0.49205  ,  0.48486  ,\n",
       "         0.026916 ,  0.091038 , -0.30984  , -0.129    ,  0.14039  ,\n",
       "         0.093296 , -0.057087 , -0.058724 , -0.27043  , -0.36084  ,\n",
       "        -0.11826  , -0.013159 ,  0.6766   ,  0.56496  ,  0.10306  ,\n",
       "         0.89588  , -0.083035 ,  0.20385  , -0.31218  , -0.78539  ,\n",
       "        -0.17744  , -0.9566   , -0.18685  , -0.65926  ,  0.16091  ,\n",
       "        -0.12383  ,  0.023029 ,  0.08357  ,  0.16348  , -0.066267 ,\n",
       "        -0.46505  , -0.42498  , -0.2844   ,  0.37591  , -1.5241   ,\n",
       "         0.58922  , -0.050554 ,  0.53357  ,  0.26322  ,  0.047219 ,\n",
       "         0.13751  ,  0.061737 , -0.043889 , -0.5096   , -0.2766   ,\n",
       "         0.14519  ,  0.20367  , -0.15443  , -0.042115 ,  0.66835  ,\n",
       "         0.068898 , -0.38482  ,  1.7868   , -0.45886  ,  0.19063  ,\n",
       "         0.15545  ,  0.10557  ,  0.17447  , -0.15255  , -0.40628  ,\n",
       "        -0.37699  ,  0.53288  , -0.025475 , -0.50639  , -0.089237 ,\n",
       "         0.80525  , -0.22466  ,  0.40134  , -0.52479  , -0.36886  ,\n",
       "        -0.12123  ,  0.25625  , -0.031981 ,  0.41846  , -0.53333  ,\n",
       "        -0.68977  ,  0.37097  ,  0.13459  , -0.17697  , -0.23335  ,\n",
       "        -0.09276  ,  0.26004  , -0.022291 ,  0.21098  , -0.40865  ,\n",
       "         0.0071628, -0.35877  ,  0.27792  , -0.37053  ,  1.5851   ,\n",
       "         0.37796  ,  0.27896  , -0.48423  , -0.12335  ,  0.028271 ,\n",
       "         1.0859   ,  0.86024  , -0.8269   ,  0.54018  ,  0.044138 ,\n",
       "         0.16097  , -0.23442  ,  0.083067 ,  0.19395  ,  0.25348  ,\n",
       "        -0.070216 ,  0.27422  ,  0.079368 , -0.60442  ,  0.15406  ,\n",
       "        -0.18175  , -0.030669 ,  0.20611  , -0.57565  , -0.3512   ,\n",
       "        -0.32589  , -0.1055   ,  0.49399  ,  0.34932  ,  0.15188  ,\n",
       "         0.20424  , -0.42786  ,  0.070315 ,  0.32806  ,  0.50217  ,\n",
       "         1.1054   , -0.47245  , -0.40336  ,  0.094475 , -0.24575  ,\n",
       "        -0.49691  ,  0.14487  ,  0.055714 ,  0.12388  , -0.075973 ,\n",
       "        -0.47409  , -0.31063  ,  0.10934  , -0.045062 , -0.11885  ,\n",
       "        -0.21459  ,  0.21724  ,  0.31083  , -0.22303  ,  0.2037   ]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "word_vector_matrix[:2]  ## these are the pretained-weights that can be used for our model building. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7636, 200)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vector_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word_vector_matrix --- It has the weights for corresponding numbers in X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,   45,  444, 3859,  777,  701,  619,   65,\n",
       "           9, 1226,   73,  117,  319,  939,  143, 2676, 1227,   58,   51,\n",
       "        3860,  130],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,   43,  320, 1374,  445,\n",
       "           1, 1766]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:2] # this is previously built with pad sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train ,X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size = 0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_size=200 \n",
    "#changing each word into a vector of size 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, vec_size, input_length = max_len, weights = [word_vector_matrix], trainable = False))\n",
    "\n",
    "model.add(Conv1D(64, 8, activation = 'relu'))\n",
    "model.add(Conv1D(64, 8, activation = 'relu'))\n",
    "model.add(MaxPooling1D(2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, kernel_initializer = 'he_normal',activation = 'relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(16, kernel_initializer = 'he_normal', activation='relu'))\n",
    "#model.add(GlobalMaxPooling1D())\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 200, 200)          1527200   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 193, 64)           102464    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 186, 64)           32832     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 93, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 5952)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                190496    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,853,537\n",
      "Trainable params: 326,337\n",
      "Non-trainable params: 1,527,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss = 'binary_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing early stopping and model check point \n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# stop training process if the accuracy of the train data is not increased after 5 epochs\n",
    "es = EarlyStopping(monitor= \"accuracy\" , min_delta= 0.01, patience= 5, verbose=1)\n",
    "\n",
    "# do not save the weights until and unless the validation accuracy is not increased.\n",
    "mc = ModelCheckpoint(filepath= \"saved models/Spam detection with Glove Vectors.h5\", monitor=\"val_accuracy\", verbose=1, save_best_only= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4457, 200)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.2046 - accuracy: 0.9219\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.97489, saving model to saved models/Spam detection with Glove Vectors.h5\n",
      "140/140 [==============================] - 7s 53ms/step - loss: 0.2046 - accuracy: 0.9219 - val_loss: 0.0847 - val_accuracy: 0.9749\n",
      "Epoch 2/20\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.0818 - accuracy: 0.9705\n",
      "Epoch 00002: val_accuracy did not improve from 0.97489\n",
      "140/140 [==============================] - 6s 45ms/step - loss: 0.0818 - accuracy: 0.9706 - val_loss: 0.1065 - val_accuracy: 0.9650\n",
      "Epoch 3/20\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.0522 - accuracy: 0.9852\n",
      "Epoch 00003: val_accuracy improved from 0.97489 to 0.98475, saving model to saved models/Spam detection with Glove Vectors.h5\n",
      "140/140 [==============================] - 7s 52ms/step - loss: 0.0528 - accuracy: 0.9850 - val_loss: 0.0821 - val_accuracy: 0.9848\n",
      "Epoch 4/20\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.0362 - accuracy: 0.9899\n",
      "Epoch 00004: val_accuracy improved from 0.98475 to 0.98655, saving model to saved models/Spam detection with Glove Vectors.h5\n",
      "140/140 [==============================] - 8s 54ms/step - loss: 0.0362 - accuracy: 0.9899 - val_loss: 0.0667 - val_accuracy: 0.9865\n",
      "Epoch 5/20\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.0284 - accuracy: 0.9899\n",
      "Epoch 00005: val_accuracy did not improve from 0.98655\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.0284 - accuracy: 0.9899 - val_loss: 0.0772 - val_accuracy: 0.9839\n",
      "Epoch 6/20\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.0195 - accuracy: 0.9937\n",
      "Epoch 00006: val_accuracy did not improve from 0.98655\n",
      "140/140 [==============================] - 7s 52ms/step - loss: 0.0195 - accuracy: 0.9937 - val_loss: 0.1111 - val_accuracy: 0.9865\n",
      "Epoch 7/20\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.0159 - accuracy: 0.9964\n",
      "Epoch 00007: val_accuracy did not improve from 0.98655\n",
      "140/140 [==============================] - 7s 53ms/step - loss: 0.0158 - accuracy: 0.9964 - val_loss: 0.0893 - val_accuracy: 0.9857\n",
      "Epoch 8/20\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.9980\n",
      "Epoch 00008: val_accuracy improved from 0.98655 to 0.98744, saving model to saved models/Spam detection with Glove Vectors.h5\n",
      "140/140 [==============================] - 8s 55ms/step - loss: 0.0073 - accuracy: 0.9980 - val_loss: 0.1056 - val_accuracy: 0.9874\n",
      "Epoch 9/20\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9993\n",
      "Epoch 00009: val_accuracy did not improve from 0.98744\n",
      "140/140 [==============================] - 7s 53ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.1243 - val_accuracy: 0.9848\n",
      "Epoch 10/20\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9989\n",
      "Epoch 00010: val_accuracy did not improve from 0.98744\n",
      "140/140 [==============================] - 7s 52ms/step - loss: 0.0023 - accuracy: 0.9989 - val_loss: 0.1440 - val_accuracy: 0.9848\n",
      "Epoch 11/20\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9980\n",
      "Epoch 00011: val_accuracy did not improve from 0.98744\n",
      "140/140 [==============================] - 7s 52ms/step - loss: 0.0052 - accuracy: 0.9980 - val_loss: 0.1751 - val_accuracy: 0.9839\n",
      "Epoch 12/20\n",
      "139/140 [============================>.] - ETA: 0s - loss: 0.0212 - accuracy: 0.9946\n",
      "Epoch 00012: val_accuracy did not improve from 0.98744\n",
      "140/140 [==============================] - 7s 52ms/step - loss: 0.0211 - accuracy: 0.9946 - val_loss: 0.1017 - val_accuracy: 0.9865\n",
      "Epoch 00012: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ad84ec1ac0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 20, validation_data = (X_test,y_test), callbacks=[es,mc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load saved model and Evaluate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = load_model('saved models/Spam detection with Glove Vectors.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def MetricEvaluation(x_data, y_data):\n",
    "    pred = Model.predict(x_data)\n",
    "    pred = pred > 0.5\n",
    "    print(confusion_matrix(y_data, pred))\n",
    "    print(classification_report(y_data, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3855    0]\n",
      " [   3  599]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3855\n",
      "           1       1.00      1.00      1.00       602\n",
      "\n",
      "    accuracy                           1.00      4457\n",
      "   macro avg       1.00      1.00      1.00      4457\n",
      "weighted avg       1.00      1.00      1.00      4457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# metric evaluation for train data\n",
    "MetricEvaluation(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[967   3]\n",
      " [ 11 134]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       970\n",
      "           1       0.98      0.92      0.95       145\n",
      "\n",
      "    accuracy                           0.99      1115\n",
      "   macro avg       0.98      0.96      0.97      1115\n",
      "weighted avg       0.99      0.99      0.99      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# metric evaluation for test data\n",
    "MetricEvaluation(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting New Data\n",
    "* **spam = 1**\n",
    "* **ham = 0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encode(x):\n",
    "    x = DataCleaner(x)\n",
    "    x = token.texts_to_sequences([x])\n",
    "    x = pad_sequences(x, maxlen = max_len, padding = 'pre')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = get_encode('u won a free ticket to singapore for a tour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The message is Spam!\n"
     ]
    }
   ],
   "source": [
    "pred = (model.predict(result) > 0.5).astype('int32')\n",
    "if pred == 1:\n",
    "    print(\"The message is Spam!\")\n",
    "else:\n",
    "    print(\"The message is not a Spam!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
